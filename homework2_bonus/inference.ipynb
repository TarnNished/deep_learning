{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-10T19:14:06.357457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure the directory exists\n",
    "results_dir = './Simpsons/models'\n",
    "os.makedirs(results_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "# Define your CNN model (2-class model)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 8 * 8, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(torch.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Function to recursively find all image files in the directory\n",
    "def find_images(data_dir):\n",
    "    image_files = []\n",
    "    for root, _, files in os.walk(data_dir):  # Walk through all subdirectories\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):  # Check image extensions\n",
    "                image_files.append(os.path.join(root, file))  # Add image file path\n",
    "    return image_files\n",
    "\n",
    "# Inference function\n",
    "def infer(data_dir, model_path, classes_file='./Simpsons/model/classes.json', results_file='./Simpsons/models/results.json'):\n",
    "    with open(classes_file, 'r') as f:\n",
    "        classes = json.load(f)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CNN(num_classes=2).to(device)  # Use 2 classes for the binary classification model\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    results = {}\n",
    "    image_files = find_images(data_dir)  # Get all images from subdirectories\n",
    "    print(f\"Found {len(image_files)} images to process...\")\n",
    "\n",
    "    for image_path in tqdm(image_files, desc=\"Processing Images\"):\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            predicted_class = classes[predicted.item()]\n",
    "            results[os.path.basename(image_path)] = predicted_class  # Save result by image name\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    # Ensure the results directory exists before saving the results\n",
    "    os.makedirs(os.path.dirname(results_file), exist_ok=True)\n",
    "\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(f\"Inference complete! Processed {len(results)} images and saved results to '{results_file}'.\")\n",
    "    return results\n",
    "\n",
    "# Run inference\n",
    "infer('./Simpsons/archive', './Simpsons/model/model_best.pth', './Simpsons/model/classes.json')\n"
   ],
   "id": "42810653",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16765 images to process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   8%|â–Š         | 1373/16765 [00:32<06:14, 41.07it/s]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
